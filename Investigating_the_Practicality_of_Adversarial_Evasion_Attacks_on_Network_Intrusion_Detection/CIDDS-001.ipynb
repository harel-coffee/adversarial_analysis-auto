{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmWYMvp_A4_M"
   },
   "source": [
    "# Investigating the Practicality of Adversarial Evasion Attacks on Network Intrusion Detection (CIDDS-001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYr9FidOIOLW"
   },
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CzFYfiRmIJri",
    "outputId": "cf8ed143-2e75-41ad-a78e-660e1fe7722c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import copy\n",
    "import time as time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#!pip install adversarial-robustness-toolbox >/dev/null\n",
    "import os,sys\n",
    "sys.path.append(os.path.dirname('../adversarial-robustness-toolbox/'))\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, DeepFool, CarliniL2Method, CarliniLInfMethod\n",
    "from art.classifiers import PyTorchClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-KDXZmOI_fJ"
   },
   "source": [
    "## CIDDS Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzucpNF9JJq0"
   },
   "source": [
    "### Dowloading and importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "wRL6avqAI58a",
    "outputId": "2848cc35-638e-430e-9949-ce1dc4f2379c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-26 10:10:00--  https://www.hs-coburg.de/fileadmin/hscoburg/WISENT-CIDDS-001.zip\n",
      "Resolving www.hs-coburg.de (www.hs-coburg.de)... 192.129.27.193\n",
      "Connecting to www.hs-coburg.de (www.hs-coburg.de)|192.129.27.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 381232494 (364M) [application/zip]\n",
      "Saving to: ‘WISENT-CIDDS-001.zip’\n",
      "\n",
      "WISENT-CIDDS-001.zi 100%[===================>] 363.57M   576KB/s    in 11m 1s  \n",
      "\n",
      "2021-05-26 10:21:01 (564 KB/s) - ‘WISENT-CIDDS-001.zip’ saved [381232494/381232494]\n",
      "\n",
      "Archive:  WISENT-CIDDS-001.zip\n",
      "   creating: CIDDS-001/\n",
      "   creating: CIDDS-001/attack_logs/\n",
      "  inflating: CIDDS-001/attack_logs/attack_logs_extern.csv  \n",
      "  inflating: CIDDS-001/attack_logs/attack_logs_intern.csv  \n",
      "   creating: CIDDS-001/client_confs/\n",
      "  inflating: CIDDS-001/client_confs/192.168.200.4.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.200.5.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.200.8.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.200.9.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.210.4.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.210.5.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.10.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.11.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.12.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.13.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.14.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.15.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.16.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.4.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.5.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.6.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.7.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.8.conf  \n",
      "  inflating: CIDDS-001/client_confs/192.168.220.9.conf  \n",
      "   creating: CIDDS-001/client_logs/\n",
      "  inflating: CIDDS-001/client_logs/192.168.200.4.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.200.5.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.200.8.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.200.9.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.210.4.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.210.5.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.10.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.11.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.12.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.13.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.14.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.15.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.16.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.4.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.5.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.6.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.7.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.8.log  \n",
      "  inflating: CIDDS-001/client_logs/192.168.220.9.log  \n",
      "  inflating: CIDDS-001/Technical Report.pdf  \n",
      "   creating: CIDDS-001/traffic/\n",
      "   creating: CIDDS-001/traffic/ExternalServer/\n",
      "  inflating: CIDDS-001/traffic/ExternalServer/CIDDS-001-external-week1.csv  \n",
      "  inflating: CIDDS-001/traffic/ExternalServer/CIDDS-001-external-week2.csv  \n",
      "  inflating: CIDDS-001/traffic/ExternalServer/CIDDS-001-external-week3.csv  \n",
      "  inflating: CIDDS-001/traffic/ExternalServer/CIDDS-001-external-week4.csv  \n",
      "   creating: CIDDS-001/traffic/OpenStack/\n",
      "  inflating: CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week1.csv  \n",
      "  inflating: CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week2.csv  \n",
      "  inflating: CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week3.csv  \n",
      "  inflating: CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week4.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amine/anaconda3/envs/advids/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Downloading and extracting the dataset if it doesn't exist\n",
    "!if [ ! -d \"./CIDDS-001\" ]; then wget https://www.hs-coburg.de/fileadmin/hscoburg/WISENT-CIDDS-001.zip; unzip WISENT-CIDDS-001.zip; fi \n",
    "#Importing the training and testing datasets from .CSV to Pandas DataFrames\n",
    "df_training = pd.read_csv('./CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week1.csv')\n",
    "df_testing = pd.read_csv('./CIDDS-001/traffic/OpenStack/CIDDS-001-internal-week2.csv')\n",
    "# Stack the training and test sets\n",
    "data = pd.concat([df_training, df_testing], axis=0)\n",
    "\n",
    "#data = data.iloc[:100000, :]\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZEBgnPxJW6j"
   },
   "source": [
    "### Removing unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckN7Jw_OJdTN"
   },
   "outputs": [],
   "source": [
    "data.drop(['Src IP Addr','Dst IP Addr', 'attackType', 'attackID', 'attackDescription', 'Flows'], inplace=True, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Timestamp feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Datetime'] = pd.to_datetime(data['Date first seen'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "data['Timestamp'] = data.Datetime.values.astype(np.int64) // 10 ** 6\n",
    "#data['Weekday'] = data.Datetime.dt.weekday\n",
    "data.drop(['Date first seen','Datetime'], inplace=True, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating source and destination port class features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Src Pt:WellKnown'] = (data['Src Pt'] < 1024).astype(float)\n",
    "#data['Src Pt:Registered'] = (data['Src Pt'] >= 1024 and data['Src Pt'] < 49152).astype(int) # didn't work\n",
    "data['Src Pt:Registered'] = ((data['Src Pt'] >= 1024).astype(float) * (data['Src Pt'] < 49152).astype(float)).astype(float)\n",
    "data['Src Pt:Dynamic'] = (data['Src Pt'] >= 49152).astype(float)\n",
    "data.drop(['Src Pt'], inplace=True, axis=1)\n",
    "\n",
    "data['Dst Pt:WellKnown'] = (data['Dst Pt'] < 1024).astype(float)\n",
    "#data['Dst Pt:Registered'] = (data['Dst Pt'] >= 1024 and data['Dst Pt'] < 49152).astype(int) # didn't work\n",
    "data['Dst Pt:Registered'] = ((data['Dst Pt'] >= 1024).astype(float) * (data['Dst Pt'] < 49152).astype(float)).astype(float)\n",
    "data['Dst Pt:Dynamic'] = (data['Dst Pt'] >= 49152).astype(float)\n",
    "data.drop(['Dst Pt'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YhAWbR2BJsms"
   },
   "source": [
    "### Transforming the problem into binary clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ps4JWj7hJ0j-"
   },
   "outputs": [],
   "source": [
    "# Labels as normal or attack (0/1)\n",
    "data['Label'] = (data['class'] != 'normal').astype(float)\n",
    "data.drop(['class'], inplace=True, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IY72JDkDJ8fZ"
   },
   "source": [
    "### One Hot Encoding the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqLzA5xzKE6S"
   },
   "outputs": [],
   "source": [
    "#for i in ['Weekday', 'Proto', 'Flags']:\n",
    "for i in ['Proto', 'Flags']:\n",
    "    # Create the One Hot Encode DataFrame\n",
    "    print(i)\n",
    "    dum = pd.get_dummies(data[i], dtype=float)\n",
    "    # Insert into the dataset DataFrame by Series\n",
    "    for column_name in list(dum.columns):\n",
    "        new_column = str(i)+':'+str(column_name)\n",
    "        data.insert(1,new_column , dum[column_name])\n",
    "    # Drop the old attribute's column\n",
    "    data.drop(i, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Bytes from str to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bytes from str to float\n",
    "data['Bytes'].astype(str)\n",
    "data['Bytes'] = data['Bytes'].apply(lambda x: x.replace(' ', '') if type(x) == str else x)\n",
    "data['Bytes'] = data['Bytes'].apply(lambda x: (float(x[:-1])* 10**20) if type(x) == str and x[-1] == 'M' else float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofSVMjNSKYPp"
   },
   "source": [
    "### Spliting the training and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zJU5gyGKcEB"
   },
   "outputs": [],
   "source": [
    "# Split training and test sets\n",
    "df_training = data[:df_training.shape[0]]    \n",
    "df_testing = data[df_training.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsjviwI7KIc1"
   },
   "source": [
    "### Normalizing the data using Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "TuDGFomBKP1l",
    "outputId": "9307af80-554a-41e7-b41e-ccbb30a2bb7d"
   },
   "outputs": [],
   "source": [
    "# Min-Max normalization on the non binary features\n",
    "for i in ['Duration', 'Packets', 'Bytes', 'Tos', 'Timestamp']:\n",
    "    # The min and max are only computed from the training set\n",
    "    min = df_training[i].min()\n",
    "    max = df_training[i].max()\n",
    "    df_training[i] = ((df_training[i] - min) / (max - min)) \n",
    "    df_testing[i] = ((df_testing[i] - min) / (max - min)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stMNv0C-Lw5V"
   },
   "source": [
    "### Convert the training and testing set into NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Pa51jRiL39N"
   },
   "outputs": [],
   "source": [
    "# Get NumPy arrays from DataFrames\n",
    "nd_training = df_training.values\n",
    "nd_testing = df_testing.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhhq7PClMAZN"
   },
   "source": [
    "### Extracting the labels and making copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8qQrNKVMExe"
   },
   "outputs": [],
   "source": [
    "# Separating arguments (x) from lables (y)\n",
    "x_train = nd_training[:, :-1]\n",
    "y_train = nd_training[:, -1]\n",
    "x_test = nd_testing[:, :-1]\n",
    "y_test = nd_testing[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FaHQn0KBMJgz"
   },
   "source": [
    "## Neural Network Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DX40cQe1MQ0H"
   },
   "source": [
    "### Convert the training and testing set into PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrpWo4BcMIRn"
   },
   "outputs": [],
   "source": [
    "# Convert from numpy array to torch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtWXR5RaO40r"
   },
   "source": [
    "### Define a neural network with 2 ReLU hidden layers and a Softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UizcDVxqO3_A"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' A basic neural network model '''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()         #python2 : super(MLP, self).__init__()\n",
    "        #defining the network's operations\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc3 = nn.Linear(hidden_size[1], output_size)\n",
    "\n",
    "    def forward(self, x, softmax=False): \n",
    "        a = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x.float())))))\n",
    "        if softmax:\n",
    "            y_pred = F.softmax(a, dim=1)\n",
    "        else:\n",
    "            y_pred = a\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNRHSdafPN-q"
   },
   "source": [
    "### Define a function to compute the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e0BvbFUPVtZ"
   },
   "outputs": [],
   "source": [
    "def evaluate_predictions(predictions, real):\n",
    "    ''' Evaluates the accuracy of the predictions'''\n",
    "    n_correct = torch.eq(predictions, real).sum().item()\n",
    "    accuracy = n_correct / len(predictions) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOwiOdMyPcMF"
   },
   "source": [
    "### Define a function that prints the models perfomance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1aB1Z_3PjMj"
   },
   "outputs": [],
   "source": [
    "def stat_model(model, x_train, y_train, x_test, y_test):\n",
    "    ''' Prints statistics about the model performances on the dataset'''\n",
    "    _, predictions_train = model(x_train, softmax=True).max(dim=1)\n",
    "    #_, predictions_train = model(x_train).max(dim=1)\n",
    "    accuracy_train = evaluate_predictions(predictions=predictions_train.long(), real=y_train)\n",
    "\n",
    "    _, predictions_test = model(x_test, softmax=True).max(dim=1)\n",
    "    #_, predictions_test = model(x_test).max(dim=1)\n",
    "    accuracy_test = evaluate_predictions(predictions=predictions_test.long(), real=y_test)\n",
    "    \n",
    "    print(\"Final Training Accuracy: {0:.4f}%\\nFinal Testing Accuracy : {1:.4f}%\"\n",
    "          .format(accuracy_train, accuracy_test))\n",
    "    # Move the tensors back to CPU\n",
    "    label_test_final = y_test.cpu().numpy()\n",
    "    predictions_test_final = predictions_test.cpu().numpy()\n",
    "    report = classification_report(label_test_final, predictions_test_final)\n",
    "    print(\"Classification Report :\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBO2uZVxPmEJ"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "xHA_5qGMPk45",
    "outputId": "2c969de5-1bb3-40e2-8982-32defb61c45a"
   },
   "outputs": [],
   "source": [
    "# Initialising the model\n",
    "input_size=x_train.shape[1]\n",
    "hidden_size=[16,16]\n",
    "output_size=2\n",
    "model = Network(input_size, hidden_size, output_size)\n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on : {}\".format(device))\n",
    "\n",
    "# Transfering model and data to GPU\n",
    "model = model.to(device)\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Setting the Loss function and Adam learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Variables to store the best performences (weights and accuracy)\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# DataFrame for the learning curve plot\n",
    "trace = pd.DataFrame(columns=['epoch', 'train_acc', 'test_acc'])\n",
    "# Iterrating on the dataset\n",
    "since = time.time()\n",
    "for epoch in range(1000+1):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train) \n",
    "    # torch.max(dim=1) returns the maximum value of each line AND its index\n",
    "    _, predictions = y_pred.max(dim=1)\n",
    "    # Compute accuracy\n",
    "    accuracy_train = evaluate_predictions(predictions=predictions.long(), real=y_train)\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Testing model on the test set\n",
    "    if epoch%10 == 0:\n",
    "        _, predictions_test = model(x_test, softmax=True).max(dim=1)\n",
    "        accuracy_test = evaluate_predictions(predictions=predictions_test.long(), real=y_test)\n",
    "        # Keep track of the accuracies for the learning curve\n",
    "        trace = trace.append([{'epoch':epoch,\n",
    "                                'train_acc':accuracy_train,\n",
    "                                'test_acc':accuracy_test}])\n",
    "        # Save the best model's accuracy and parameters\n",
    "        if accuracy_test > best_accuracy:\n",
    "            best_accuracy = accuracy_test\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        # Displap statistics\n",
    "        if epoch%100 == 0:\n",
    "            time_elapsed = time.time() - since\n",
    "            print(\"epoch: {0:4d} | loss: {1:.4f} | Train accuracy: {2:.4f}% | Test accuracy: {3:.4f}% [{4:.4f}%] | Running for : {5:.0f}m {6:.0f}s\"\n",
    "                  .format(epoch,\n",
    "                          loss,\n",
    "                          accuracy_train,\n",
    "                          accuracy_test,\n",
    "                          best_accuracy,\n",
    "                          time_elapsed // 60,\n",
    "                          time_elapsed % 60))\n",
    "\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "# Compute the training time\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IqslUHHRjfl"
   },
   "source": [
    "### Display the learning curve and the model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "id": "uIfrxK78RobZ",
    "outputId": "a2ee1d5d-0096-4913-8270-d61cf40f5731"
   },
   "outputs": [],
   "source": [
    "# Draw the learning curve\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(data=trace, x='epoch', y='train_acc', c=\"b\", s=5)\n",
    "plt.scatter(data=trace, x='epoch', y='test_acc', c=\"r\", s=5)\n",
    "plt.plot(trace['epoch'], trace['train_acc'], c=\"b\")\n",
    "plt.plot(trace['epoch'], trace['test_acc'], c=\"r\")\n",
    "plt.ylim((0, 100))\n",
    "plt.yticks(np.arange(0, 100, 5))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(\"learning_curve.eps\", format=\"eps\", bbox_inches='tight')\n",
    "\n",
    "# Loading the best weights and displaying the best model's performances\n",
    "model.load_state_dict(best_model_weights)\n",
    "stat_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUUZasB2CSx3"
   },
   "source": [
    "### Saving/Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "opZmOHI7CYfG",
    "outputId": "9cbc8c18-2db4-45ed-856a-5664aa0716f9"
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"./model-cidds.pytorch\")\n",
    "model.load_state_dict(torch.load(\"./model-cidds.pytorch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2yiT2olRN9F"
   },
   "source": [
    "## Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0X0sHszZR39m"
   },
   "source": [
    "### Define a table for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPX4nhBSQ-4S"
   },
   "outputs": [],
   "source": [
    "adv_feat_stats = pd.DataFrame(index=df_training.columns[:-1])\n",
    "\n",
    "adv_results = pd.DataFrame(index=['Accuracy', \n",
    "                                  'Mean perturbed features   [Mean L0]', \n",
    "                                  'Max perturbed features    [Max  L0]', \n",
    "                                  'Mean Euclidiant distance  [Mean L2]', \n",
    "                                  'Max Euclidiant distance   [Max  L2]', \n",
    "                                  'Mean Maximum perturbation [Mean Li]', \n",
    "                                  'Max Maximum perturbation  [Max  Li]'])\n",
    "\n",
    "adv_inv = pd.DataFrame(index=['Invalid value range',\n",
    "                              'Invalid binary values',\n",
    "                              'Invalid class belonging'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ziF5wllSF40"
   },
   "source": [
    "### Define a function to compute Lp norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stOmGKtsSOgP"
   },
   "outputs": [],
   "source": [
    "def adv_norms(x_test_cpu, adversarial_examples_cpu):\n",
    "    mean_l0 = np.mean(np.sum(x_test_cpu != adversarial_examples_cpu, axis=1))\n",
    "    max_l0 = np.max(np.sum(x_test_cpu != adversarial_examples_cpu, axis=1))\n",
    "    mean_l2 = np.mean(np.sum(np.power(x_test_cpu - adversarial_examples_cpu, 2), axis=1, keepdims=True))\n",
    "    max_l2 = np.max(np.sum(np.power(x_test_cpu - adversarial_examples_cpu, 2), axis=1, keepdims=True))\n",
    "    mean_li = np.mean(np.max(np.abs(x_test_cpu - adversarial_examples_cpu), axis=1, keepdims=True))\n",
    "    max_li = np.max(np.max(np.abs(x_test_cpu - adversarial_examples_cpu), axis=1, keepdims=True))\n",
    "    return [mean_l0, max_l0, mean_l2, max_l2, mean_li, max_li]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpY9NnU_epZg"
   },
   "source": [
    "### Define a function to check the invalidation criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBPTYOn0epMy"
   },
   "outputs": [],
   "source": [
    "def adv_criteria(x_test_cpu, adversarial_examples_cpu):\n",
    "    # Verify value ranges\n",
    "    min = x_test_cpu.min(axis=1, keepdims=True)\n",
    "    max = x_test_cpu.max(axis=1, keepdims=True)\n",
    "    adv_range = (adversarial_examples_cpu < min) | (adversarial_examples_cpu > max)\n",
    "    adv_range = adv_range.any(axis=1, keepdims=True)\n",
    "    adv_range = adv_range.sum(axis=0)\n",
    "    #print(\"proportion of out-of-range values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    # Binary values\n",
    "    binary_feat_ind = list(range(1,25)) + list(range(29,35))\n",
    "    adv_bin = adversarial_examples_cpu[:, binary_feat_ind]\n",
    "    adv_bin = (adv_bin != 1) & ( adv_bin != 0)\n",
    "    adv_bin = adv_bin.any(axis=1, keepdims=True)\n",
    "    adv_bin = adv_bin.sum(axis=0)\n",
    "    #print(\"proportion of non-binary values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    # Multi class\n",
    "    # Flag\n",
    "    adv1 = adversarial_examples_cpu[:, 1:21] != 0\n",
    "    adv1 = adv1.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv1 = adv1.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Proto\n",
    "    adv2 = adversarial_examples_cpu[:, 21:25] != 0\n",
    "    adv2 = adv2.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv2 = adv2.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Src Pt\n",
    "    adv3 = adversarial_examples_cpu[:, 29:32] != 0\n",
    "    adv3 = adv3.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv3 = adv3.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Dst Pt\n",
    "    adv4 = adversarial_examples_cpu[:, 32:35] != 0\n",
    "    adv4 = adv3.astype(int).sum(axis=1, keepdims=True) != 1\n",
    "    adv4 = adv3.sum(axis=1, keepdims=True)\n",
    "\n",
    "    adv_cat = adv1 | adv2 | adv3 | adv4\n",
    "    adv_cat = adv_cat.sum(axis=0)\n",
    "    #print(\"proportion of multiple category values : {:.2f}% | {}/{}\".format(adv[0]*100/x_test.shape[0], adv[0], x_test.shape[0]))\n",
    "\n",
    "    return [adv_range[0]*100/x_test.shape[0], adv_bin[0]*100/x_test.shape[0], adv_cat[0]*100/x_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhcKW1IMSVVz"
   },
   "source": [
    "### Extracte the attacks samples and copy them in the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yMQum6QSc2z"
   },
   "outputs": [],
   "source": [
    "positive_examples = df_testing[df_testing['Label'] == 1].values\n",
    "x_test = torch.from_numpy((positive_examples[:, :-1])).float()\n",
    "y_test = torch.from_numpy((positive_examples[:, -1])).float()\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugfmnV21LNEx"
   },
   "source": [
    "### Define the model in ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOPhKGp2LM23"
   },
   "outputs": [],
   "source": [
    "# Applying the PyTorch wrapper\n",
    "classifier = PyTorchClassifier(model=model, loss=criterion, optimizer=optimizer, input_shape=input_size, nb_classes=output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_TFB2IcSk0d"
   },
   "source": [
    "### Clean Data\n",
    "The model performance on untouched attack samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "ofkaYZoYSpwG",
    "outputId": "919477eb-9cd7-4dec-9f76-0d7d543e4c6c"
   },
   "outputs": [],
   "source": [
    "_, predictions_clean = model(x_test, softmax=True).max(dim=1)\n",
    "accuracy_clean = evaluate_predictions(predictions=predictions_clean.long(), real=y_test)\n",
    "\n",
    "attack='Clean'\n",
    "\n",
    "# Exporting the clean examples in a .csv file\n",
    "pd.DataFrame(np.hstack((x_test.cpu().numpy(),y_test.cpu().numpy().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"clean_examples.csv\")\n",
    "\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "adv_results[attack] = [accuracy_clean] + adv_norms(x_test_cpu, x_test_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, x_test_cpu)\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_L4sJYvbTF-Y"
   },
   "source": [
    "### Fast Gradient Sign Method\n",
    "*Goodfellow et al. (2015) \"Explaining and Harnessing Adversarial Examplse\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "1DKFhHZnTkyk",
    "outputId": "a96db7c5-0163-4c7b-cd92-2ac269c3ae6c"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = FastGradientMethod(classifier,\n",
    "                                         norm=np.inf,\n",
    "                                         eps=0.1,\n",
    "                                         targeted=False,\n",
    "                                         num_random_init=0,\n",
    "                                         batch_size=128,\n",
    "                                         )\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'FGSM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_FGSM.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btrkyYmgZAOw"
   },
   "source": [
    "### Basic Iterative Method\n",
    "\n",
    "*Kurakin et al. (2016) \"Adversarial examples in the physical world\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "0jV3uIUxZEBg",
    "outputId": "2b2276f8-a394-468a-c629-a8f9afebc427"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = BasicIterativeMethod(classifier, \n",
    "                                           eps=0.1, \n",
    "                                           eps_step=0.001,\n",
    "                                           max_iter=100, \n",
    "                                           targeted=False, \n",
    "                                           batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'BIM'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_BIM.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mw0zPmqZGzL"
   },
   "source": [
    "### DeepFool\n",
    "*Moosavi-Dezfooli et al (2016) \"DeepFool: a simple and accurate method to fool deep neural networks\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "id": "Axf8gApiZPKD",
    "outputId": "b78d0d1a-506e-4595-cfb0-10cc91d1768e"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = DeepFool(classifier, \n",
    "                               max_iter=100, \n",
    "                               epsilon=1e-6, \n",
    "                               nb_grads=10, \n",
    "                               batch_size=128)\n",
    "\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'DF'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)            \n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_DF.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 10e-6).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wpjvuo_LZTGh"
   },
   "source": [
    "### Carlini & Wagner L2 Attack\n",
    "*Carlini et al. (2017) \"Towards Evaluating the Robustness of Neural Networks\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "8G0CIFD1Zcex",
    "outputId": "e5f439e5-6426-4a9f-df12-a8a271c7bea4"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL2Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.01,\n",
    "                                      binary_search_steps=10,\n",
    "                                      max_iter=10,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'CW2'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_CW2.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkaPGkUuZ_Jh"
   },
   "source": [
    "### Carlini & Wagner L∞ Attack\n",
    "*Carlini et al. (2017) \"Towards Evaluating the Robustness of Neural Networks\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2akJNaUaB1H"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniLInfMethod(classifier,\n",
    "                                        confidence=0.0,\n",
    "                                        targeted=False,\n",
    "                                        learning_rate=0.01,\n",
    "                                        max_iter=5,\n",
    "                                        max_halving=5,\n",
    "                                        max_doubling=5,\n",
    "                                        eps=0.1,\n",
    "                                        batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "# The transformation to tanh space introduce some small perturbation, we remove it to get the exact statistics\n",
    "adversarial_examples = pd.DataFrame(adversarial_examples)\n",
    "adversarial_examples[(np.abs(adversarial_examples - x_test_cpu) < 10e-6)] = x_test_cpu\n",
    "adversarial_examples = adversarial_examples.values\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'CW∞'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_CW∞.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLttu7yNaaf5"
   },
   "source": [
    "### Carlini & Wagner L0 Attack\n",
    "*Carlini et al. (2017) \"Towards Evaluating the Robustness of Neural Networks\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6q0aZhJahfE"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = CarliniL0Method(classifier,\n",
    "                                      confidence=0.0,\n",
    "                                      targeted=False,\n",
    "                                      learning_rate=0.01,\n",
    "                                      binary_search_steps=10,\n",
    "                                      max_iter=10,\n",
    "                                      warm_start=True,\n",
    "                                      initial_const=0.01,\n",
    "                                      max_halving=5,\n",
    "                                      max_doubling=5,\n",
    "                                      batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = pd.read_csv(\"adversarial_examples_CW0.csv\").iloc[:, 1:-1].values\n",
    "\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'CW0'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "#pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_CW0.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKPSEN8Cn9HW"
   },
   "source": [
    "### Jacobian-based Saliency Map Attack\n",
    "*Papernot et al. (2016) The limitations of deep learning in adversarial settings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3c4_vosoP1-"
   },
   "outputs": [],
   "source": [
    "# Creating the adversarial examples crafter\n",
    "adversarial_crafter = SaliencyMapMethod(classifier,\n",
    "                                        theta = 0.1,\n",
    "                                        gamma = 1.0,\n",
    "                                        batch_size=128)\n",
    "# Generating the adversarial examples\n",
    "adversarial_examples = adversarial_crafter.generate(x=x_test.cpu())\n",
    "\n",
    "adversarial_examples = torch.from_numpy(adversarial_examples).float()\n",
    "adversarial_examples = adversarial_examples.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "stat_model(model, x_test, y_test, adversarial_examples, y_test)\n",
    "\n",
    "adversarial_examples_cpu = np.array(adversarial_examples.cpu())\n",
    "x_test_cpu = np.array(x_test.cpu())\n",
    "\n",
    "_, predictions_adv = model(adversarial_examples, softmax=True).max(dim=1)\n",
    "accuracy_adv = evaluate(predictions=predictions_adv.long(), real=y_test)\n",
    "attack = 'JSMA'\n",
    "adv_results[attack] = [accuracy_adv] + adv_norms(x_test_cpu, adversarial_examples_cpu)\n",
    "adv_inv[attack] = adv_criteria(x_test_cpu, adversarial_examples_cpu)\n",
    "\n",
    "# Exporting the adversarial examples in a .csv file\n",
    "pd.DataFrame(np.hstack((adversarial_examples_cpu,y_test.cpu().reshape(y_test.shape[0], 1))), columns=data.columns).to_csv(\"adversarial_examples_JSMA.csv\")\n",
    "\n",
    "# Saving the statistics in a table\n",
    "perturbation = np.abs(adversarial_examples_cpu - x_test_cpu)\n",
    "adv_feat_stats[attack] = ((perturbation > 0).sum(axis=0) / perturbation.shape[0]) * 100\n",
    "\n",
    "print(adv_results[attack])\n",
    "print(adv_inv[attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SIBuBF-Trk4"
   },
   "source": [
    "### Statistics of the different attack methods\n",
    "The tables below show for every attack:\n",
    "- The accuracy of the model and mean/max Lp norms between the original and adversarial examples.\n",
    "- The pourcentage of examples perturbing each feature.\n",
    "- The proportion of exemples meeting the different invalidation criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRdjKOgLTlkn"
   },
   "outputs": [],
   "source": [
    "adv_results.to_csv(\"adv_results.csv\")\n",
    "adv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRjCuGWNU9TM"
   },
   "outputs": [],
   "source": [
    "adv_feat_stats.to_csv(\"adv_feat_stats.csv\")\n",
    "adv_feat_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU2zUIi9bJsB"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,15))\n",
    "\n",
    "sb.heatmap(adv_feat_stats.round(decimals=2), annot=True, cmap='YlOrRd', fmt='g')\n",
    "\n",
    "plt.savefig(\"hmap_features_stats.eps\", format=\"eps\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lsu9gki7PgAY"
   },
   "outputs": [],
   "source": [
    "adv_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Syb-8wr_SZoY"
   },
   "source": [
    "## Features analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tx7MyA6KRaDi"
   },
   "source": [
    "### Heat map of the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xG-y37yLRgjy"
   },
   "outputs": [],
   "source": [
    "numeric_features = ['Duration', 'Packets', 'Bytes', 'Tos', 'Timestamp']\n",
    "corr = df_training[numeric_features].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "im = ax.imshow(corr, cmap='RdBu', vmin=-1, vmax=1)\n",
    "\n",
    "ax.figure.colorbar(im)\n",
    "plt.yticks(np.arange(0, len(corr.columns), 1), corr.columns)\n",
    "plt.xticks(np.arange(0, len(corr.columns), 1), corr.columns, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(numeric_features)):\n",
    "    for j in range(len(numeric_features)):\n",
    "        text = ax.text(j, i, corr.iloc[i, j].round(decimals=2), ha=\"center\", va=\"center\", color=\"w\")\n",
    "        \n",
    "plt.savefig('correlation_matrix.eps', format='eps', bbox_inches='tight')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Adversarial Examples against Intrusion Detection Systems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
